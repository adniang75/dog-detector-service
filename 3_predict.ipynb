{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "\n",
    "### Project Organization\n",
    "```\n",
    ".\n",
    "├── README.md\n",
    "├── LICENSE\n",
    "├── requirements.txt        <- Used to install packages for s2i application\n",
    "├── 0_start_here.ipynb      <- Instructional notebook\n",
    "├── 1_run_flask.ipynb       <- Notebook for running flask locally to test\n",
    "├── 2_test_flask.ipynb      <- Notebook for testing flask requests\n",
    "├── .gitignore              <- standard python gitignore\n",
    "├── .s2i                    <- hidden folder for advanced s2i configuration\n",
    "│   └── environment         <- s2i environment settings\n",
    "├── gunicorn_config.py      <- configuration for gunicorn when run in OpenShift\n",
    "├── prediction.py           <- the predict function called from Flask\n",
    "└── wsgi.py                 <- basic Flask application\n",
    "```\n",
    "\n",
    "### Basic Flow\n",
    "1. Install and manage dependencies in `requirements.txt`.\n",
    "1. Experiment as usual.\n",
    "1. Extract your prediction into the `prediction.py` file.\n",
    "1. Update any dependencies.\n",
    "1. Run and test your application locally.\n",
    "1. Save to git.\n",
    "\n",
    "For a complete overview, please read the [README.md](./README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "KUu4vOt5zI9d"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "Experiment with data and create your prediction function.  Create any serialized models needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For running inference on the TF-Hub module.\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "  fig = plt.figure(figsize=(10, 10))\n",
    "  plt.grid(False)\n",
    "  plt.imshow(image)\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color,\n",
    "                               font,\n",
    "                               thickness=4,\n",
    "                               display_str_list=()):\n",
    "  \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                ymin * im_height, ymax * im_height)\n",
    "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "             (left, top)],\n",
    "            width=thickness,\n",
    "            fill=color)\n",
    "\n",
    "  # If the total height of the display strings added to the top of the bounding\n",
    "  # box exceeds the top of the image, stack the strings below the bounding box\n",
    "  # instead of above.\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = top + total_display_str_height\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                    (left + text_width, text_bottom)],\n",
    "                   fill=color)\n",
    "    draw.text((left + margin, text_bottom - text_height - margin),\n",
    "              display_str,\n",
    "              fill=\"black\",\n",
    "              font=font)\n",
    "    text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
    "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "  colors = list(ImageColor.colormap.values())\n",
    "\n",
    "  font = ImageFont.load_default()\n",
    "\n",
    "  for i in range(min(boxes.shape[0], max_boxes)):\n",
    "    if scores[i] >= min_score:\n",
    "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
    "                                     int(100 * scores[i]))\n",
    "      color = colors[hash(class_names[i]) % len(colors)]\n",
    "      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "      draw_bounding_box_on_image(\n",
    "          image_pil,\n",
    "          ymin,\n",
    "          xmin,\n",
    "          ymax,\n",
    "          xmax,\n",
    "          color,\n",
    "          font,\n",
    "          display_str_list=[display_str])\n",
    "      np.copyto(image, np.array(image_pil))\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'models/openimages_v4_ssd_mobilenet_v2_1'\n",
    "saved_model = tf.saved_model.load(model_dir)\n",
    "model = saved_model.signatures['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "  img = tf.io.read_file(path)\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detector(detector, path):\n",
    "  img = load_img(path)\n",
    "\n",
    "  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "  result = detector(converted_img)\n",
    "\n",
    "\n",
    "  result = {key:value.numpy() for key,value in result.items()}\n",
    "\n",
    "  print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
    "\n",
    "\n",
    "  image_with_boxes = draw_boxes(\n",
    "      img.numpy(), result[\"detection_boxes\"],\n",
    "      result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
    "\n",
    "  display_image(image_with_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_img = 'twodogs.jpg'\n",
    "run_detector(model, dog_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Predict Function\n",
    "\n",
    "Extract the prediction logic into a standalone python file, `prediction.py` in a `predict` function.  Also, make sure `requirements.txt` is updated with any additional packages you've used and need for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 15:51:38.412442: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 15:51:43.294234: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-13 15:51:43.313353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-13 15:51:43.313621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:1e.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-09-13 15:51:43.313655: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-13 15:51:43.327167: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-13 15:51:43.327280: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-09-13 15:51:43.331860: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-13 15:51:43.333942: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-13 15:51:43.334036: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2021-09-13 15:51:43.338719: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-09-13 15:51:43.338900: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-13 15:51:43.338918: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-09-13 15:51:43.339308: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-13 15:51:43.340572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-13 15:51:43.340595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "2021-09-13 15:51:43.418062: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-13 15:51:43.418676: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2499995000 Hz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import base64\n",
    "\n",
    "model_dir = 'models/openimages_v4_ssd_mobilenet_v2_1'\n",
    "saved_model = tf.saved_model.load(model_dir)\n",
    "detector = saved_model.signatures['default']\n",
    "\n",
    "\n",
    "def predict(body):\n",
    "    base64img = body.get('image')\n",
    "    img_bytes = base64.decodebytes(base64img.encode())\n",
    "    detections = detect(img_bytes)\n",
    "    cleaned = clean_detections(detections)\n",
    "    \n",
    "    return { 'detections': cleaned }\n",
    "\n",
    "\n",
    "def detect(img):    \n",
    "    image = tf.image.decode_jpeg(img, channels=3)\n",
    "    converted_img  = tf.image.convert_image_dtype(image, tf.float32)[tf.newaxis, ...]\n",
    "    result = detector(converted_img)\n",
    "    num_detections = len(result[\"detection_scores\"])\n",
    "    \n",
    "    output_dict = {key:value.numpy().tolist() for key, value in result.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def clean_detections(detections):\n",
    "    cleaned = []\n",
    "    # max_boxes = 10\n",
    "    # num_detections = min(detections['num_detections'], max_boxes)\n",
    "    num_detections = detections['num_detections']\n",
    "\n",
    "    for i in range(0, num_detections):\n",
    "        label = detections['detection_class_entities'][i].decode('utf-8')\n",
    "        score = detections['detection_scores'][i]\n",
    "        if label == 'Dog' and score > 0.3:\n",
    "            d = {\n",
    "                'box': {\n",
    "                    'yMin': detections['detection_boxes'][i][0],\n",
    "                    'xMin': detections['detection_boxes'][i][1],\n",
    "                    'yMax': detections['detection_boxes'][i][2],\n",
    "                    'xMax': detections['detection_boxes'][i][3]\n",
    "                },\n",
    "                'class': label,\n",
    "                'label': label,\n",
    "                'score': score,\n",
    "            }\n",
    "            cleaned.append(d)\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'box': {'yMin': 0.06668734550476074, 'xMin': 0.059880733489990234, 'yMax': 0.9051148295402527, 'xMax': 0.5364789962768555}, 'class': 'Dog', 'label': 'Dog', 'score': 0.8483346700668335}, {'box': {'yMin': 0.32391250133514404, 'xMin': 0.5251951813697815, 'yMax': 0.9843556880950928, 'xMax': 0.9758182168006897}, 'class': 'Dog', 'label': 'Dog', 'score': 0.7970173358917236}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('sample-requests/twodogs.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "result = predict(data)\n",
    "# print(len(result['detections']))\n",
    "print(result['detections'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from prediction import predict, detect\n",
    "\n",
    "\n",
    "with open('sample-requests/twodogs.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "result = predict(data)\n",
    "print(len(result['detections']))\n",
    "print(result['detections'][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Flask\n",
    "\n",
    "Run flask in a separate notebook ([1_run_flask.ipynb](./1_run_flask.ipynb)) to create a local service to try it out.  You must run the application in a separate notebook since it will use the kernel until stopped.\n",
    "\n",
    "```\n",
    "!FLASK_ENV=development FLASK_APP=wsgi.py flask run\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Flask Endpoint\n",
    "\n",
    "Head over to (notebook 4)[.4_run_flask.ipynb] to run the application, then visit (notebook 5)[5_test_flask.ipynb] to try out your model service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Object detection",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
